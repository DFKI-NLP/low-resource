{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "\"\"\"this file is output by entity_annotation_for_RE.ipynb \"\"\"\n",
    "file = r'/data2/zhanghc/RE/low-resource/src/data/entity_annotation.csv'\n",
    "df_r = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the schema used by relation labeling\n",
    "They are tag combination\n",
    "***********************************\n",
    "Component: hasAttribute\n",
    "Unit_Data_Storage\n",
    "Dimensions\n",
    "Unit_Weights\n",
    "Unit_Speed\n",
    "Unit_WriteSpeed\n",
    "Unit_Resolution\n",
    "Unit_electic_current\n",
    "Time_Span\n",
    "Size\n",
    "\n",
    "Product: hasComponent\n",
    "Component\n",
    "\n",
    "Product: hasBrand\n",
    "Brand\n",
    "\n",
    "Product:hasFeature:\n",
    "Feature\n",
    "\n",
    "Product:hasSoftware:\n",
    "Software\n",
    "************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.tokenizers import Tokenizer, WordTokenizer\n",
    "from allennlp.data.tokenizers.word_splitter import JustSpacesWordSplitter\n",
    "import re\n",
    "\n",
    "_tokenizer =  WordTokenizer(word_splitter=JustSpacesWordSplitter())\n",
    "\n",
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "\n",
    "# build up the schema to check from\n",
    "head_dict = {'COMPONENTS': {i for i in range(9)}, 'PRODUCT':{i for i in range(9,13)} }\n",
    "tail_dict = {'UNIT_DATA_STORAGE': {0}, 'DIMENSIONS': {1}, 'UNIT_WEIGHTS': {2},\n",
    "             'UNIT_SPEED': {3}, 'UNIT_WRITESPEED': {4}, 'UNIT_RESOLUTION': {5},\n",
    "             'UNIT_ELECTIC_CURRENT':{ 6 }, 'TIME_SPAN': {7 }, 'SIZE':{ 8 },\n",
    "            'COMPONENTS': {9 }, 'BRAND': {10 }, 'FEATURE': {11}, 'SOFTWARE': {12}}\n",
    "relation_tag=[\"hasAttribute\"]*9+[\"hasComponent\",\"hasBrand\",\"hasFeature\",\"hasSoftware\"]\n",
    "             \n",
    "def findIndex(text_array, token):\n",
    "    if token in text_array:\n",
    "        return text_array.index(token)\n",
    "    else:\n",
    "        for i, t in enumerate(text_array):\n",
    "            if token in t:\n",
    "                return i\n",
    "        token_new = re.sub(\"\\W$|^\\W\", \"\", token)\n",
    "        if token_new in text_array:\n",
    "            return text_array.index(token_new)\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "def find_start_end(text_array, token1, token2):\n",
    "    start = findIndex(text_array, token1)\n",
    "    if token1 == token2:\n",
    "        end = start\n",
    "    else:\n",
    "        end = findIndex(text_array, token2)\n",
    "        if start >= end: end = start\n",
    "    return start, end\n",
    "\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "738456it [00:30, 23876.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:349408\n",
      "porprotion:0.2089113540183125\n",
      "total:1672518\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_result = []\n",
    "n_positive=0\n",
    "total_n = 0\n",
    "for row in tqdm(df_r.itertuples()):\n",
    "    docid = row[2]\n",
    "    ents = row[3]\n",
    "    sentence = row[4]\n",
    "    \n",
    "    jents = json.loads(ents.replace(\"'\", \"\\\"\" ))\n",
    "    tags = [ ent[\"label\"] for ent in jents]\n",
    "    texts=[ ent[\"text\"] for ent in jents]\n",
    "    \n",
    "    ent_num = len(jents)\n",
    "  \n",
    "    if ent_num < 2 : continue\n",
    "    \n",
    "    if len(str(sentence).split(\" \"))<5:continue\n",
    "        \n",
    "    text_new = sentence.split(\" \")\n",
    "     # to find out each entity pairs\n",
    "    for i in range(ent_num):\n",
    "        head = jents[i]\n",
    "        head_text = sentence[head['start_char']:head['end_char']]\n",
    "        head_token = head_text.split(\" \")  # self._tokenizer.tokenize(head_text)\n",
    "        head_start, head_end = find_start_end(text_new, head_token[0], head_token[-1])\n",
    "        \n",
    "        for j in range(ent_num):\n",
    "            if i == j:continue\n",
    "       \n",
    "            tail = jents[j]\n",
    "            \n",
    "            tail_text = sentence[tail['start_char']:tail['end_char']]\n",
    "            \n",
    "            if str(head_text.lower()) == str(tail_text.lower()):continue\n",
    "        \n",
    "            tail_token = tail_text.split(\" \")  \n",
    "            tail_start, tail_end = find_start_end(text_new, tail_token[0], tail_token[-1])\n",
    "            \n",
    "            label_name = \"None\"\n",
    "            if head['label'] in head_dict and tail['label'] in tail_dict:\n",
    "                relation_ = head_dict[head['label']].intersection(tail_dict[tail['label']])\n",
    "                label_name = relation_tag[relation_.pop()] if len(relation_)>0 else\"None\"\n",
    "            \n",
    "            if label_name == \"hasAttribute\":\n",
    "                #Re-judge the attribute relationship of the component whether correctly labeled\n",
    "                tag_span = tags[i+1:j] if i<j else tags[j+1:i]\n",
    "                if \"COMPONENTS\" in tag_span:\n",
    "                    re_label = \"None\"\n",
    "         \n",
    "            line_json={\"id\": docid, \"sent\": sentence, \"label\": label_name, \"entities\": [[head_start,head_end],[tail_start,tail_end]],\n",
    "                       \"head_text\":head_text,\n",
    "                  \"tail_text\":tail_text}\n",
    "            \n",
    "            \"\"\"each line only contains one relation. the same sentence repeat in different pair of entitis.\"\"\"\n",
    "            \n",
    "            output_result.append(line_json)  \n",
    "            \n",
    "            if label_name != \"None\":n_positive+=1\n",
    "            total_n+=1\n",
    "\n",
    "print(\"positive:\"+str(n_positive))\n",
    "print(\"porprotion:\"+str(float(n_positive/total_n)) )           \n",
    "random.shuffle(output_result)\n",
    "\n",
    "\"\"\"we split train/dev dataset and write down\"\"\"\n",
    "\n",
    "path_out_train=\"/data2/zhanghc/RE/low-resource/src/data/distantly_labeled/relation_annotation_train.csv\"\n",
    "path_out_dev=\"/data2/zhanghc/RE/low-resource/src/data/distantly_labeled/relation_annotation_dev.csv\"\n",
    "proportion_len = int(len(output_result)* 0.7)\n",
    "with open(path_out_train, 'w') as out_f:\n",
    "    for inst in output_result[:proportion_len]:\n",
    "        out_f.write(json.dumps(inst) + '\\n')\n",
    "with open(path_out_dev, 'w') as out_f:\n",
    "    for inst in output_result[proportion_len:]:\n",
    "        out_f.write(json.dumps(inst) + '\\n')\n",
    "          \n",
    "print(\"total:\"+str(len(output_result)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
